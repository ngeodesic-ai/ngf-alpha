{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd04fe92-3b48-4212-98c6-8ff832de567b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--mode {geodesic,nudge}] [--seed SEED]\n",
      "                             [--target-var TARGET_VAR]\n",
      "                             [--pca-min-dims PCA_MIN_DIMS]\n",
      "                             [--pca-max-dims PCA_MAX_DIMS] [--lam LAM]\n",
      "                             [--dt DT] [--steps STEPS] [--gamma GAMMA]\n",
      "                             [--tau TAU] [--mass-scale MASS_SCALE]\n",
      "                             [--early-stop-window EARLY_STOP_WINDOW]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f /Users/ian_moore/Library/Jupyter/runtime/kernel-62599595-5092-499d-ae39-58dfb97245aa.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/IPython/core/interactiveshell.py:3585: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Stage 10 — ARC-12 patched benchmark\n",
    "\n",
    "What changed (quick summary):\n",
    "- Stronger, orientation-aware classifier to separate flip_h vs flip_v.\n",
    "- Balanced class priors and temperature-calibrated probabilities.\n",
    "- PCA is standardized + whitened; components picked by variance with safe caps.\n",
    "- Fused score = w_cos * cosine + w_maha * (−mahalanobis²) + w_orient * orientation logit.\n",
    "- LDA (shared covariance) used for stability; optional QDA.\n",
    "- Sanity block prints per-class mean distances + confusion matrix.\n",
    "\n",
    "Run:\n",
    "  python3 latest-arc-benchmark_patched.py --device cpu\n",
    "\n",
    "Notes:\n",
    "- Uses GPT-2 mean-pooled hidden states (dim=768) as latents.\n",
    "- The tiny demo datasets below keep the file self‑contained. Swap them with yours if needed.\n",
    "\"\"\"\n",
    "from __future__ import annotations\n",
    "import argparse\n",
    "import math\n",
    "import random\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Tuple, Dict\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from numpy.linalg import inv\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "\n",
    "# ---------------------------\n",
    "# Repro & config\n",
    "# ---------------------------\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "DEVICE_DEFAULT = \"cpu\"\n",
    "\n",
    "# PCA / classifier knobs\n",
    "PCA_TARGET_VAR = 0.996  # target cumulative variance\n",
    "PCA_MIN = 6\n",
    "PCA_MAX = 32\n",
    "PCA_WHITEN = True\n",
    "\n",
    "# scoring fusion weights\n",
    "W_COS = 0.60\n",
    "W_MAHA = 0.35\n",
    "W_ORIENT = 0.25\n",
    "TEMP = 1.25  # softmax temperature for probs\n",
    "MARGIN_ROTATE = 0.05  # require rotate to beat flips by this much, or reassign to closer flip\n",
    "\n",
    "# ---------------------------\n",
    "# Tiny demo data (replace with your full sets)\n",
    "# ---------------------------\n",
    "TRAIN: Dict[str, List[str]] = {\n",
    "    \"rotate\": [\n",
    "        \"Rotate 90° cw: [[1,2],[3,4]] -> [[3,1],[4,2]]. Apply rotation.\",\n",
    "        \"Perform a right rotation: [[5,6],[7,8]] → [[7,5],[8,6]].\",\n",
    "        \"Rotate 90 deg clockwise the 2x2 grid [[2,1],[4,3]].\",\n",
    "        \"Turn the grid right by 90 degrees: [[9,8],[7,6]].\",\n",
    "        \"Apply 90° rotation to [[1,3],[2,4]].\",\n",
    "        \"Quarter-turn clockwise the matrix [[4,1],[6,2]].\",\n",
    "        \"Rotate right: [[a,b],[c,d]] ⇒ [[c,a],[d,b]].\",\n",
    "        \"Clockwise rotation example on a 2×2 grid.\",\n",
    "        \"Rotate 90° cw pattern transformation instruction.\",\n",
    "        \"Use a 90-degree clockwise operation to map input to output.\"\n",
    "    ],\n",
    "    \"flip_h\": [\n",
    "        \"Flip horizontally: [[1,2],[3,4]] -> [[2,1],[4,3]].\",\n",
    "        \"Mirror left-right: [[5,6],[7,8]] → [[6,5],[8,7]].\",\n",
    "        \"Apply horizontal reflection across the vertical axis.\",\n",
    "        \"Left-right mirror flip for a 2x2 grid.\",\n",
    "        \"Perform horizontal flip on the matrix [[a,b],[c,d]].\",\n",
    "        \"Reflect across the y-axis (swap columns).\",\n",
    "        \"Horizontal mirror operation on small grid.\",\n",
    "        \"Use left-right symmetry to transform the pattern.\",\n",
    "        \"LR reflection mapping instruction.\",\n",
    "        \"Flip left to right on the given grid.\"\n",
    "    ],\n",
    "    \"flip_v\": [\n",
    "        \"Flip vertically: [[1,2],[3,4]] -> [[3,4],[1,2]].\",\n",
    "        \"Mirror top-bottom: [[5,6],[7,8]] → [[7,8],[5,6]].\",\n",
    "        \"Apply vertical reflection across the horizontal axis.\",\n",
    "        \"Top-bottom mirror flip for a 2x2 grid.\",\n",
    "        \"Perform vertical flip on the matrix [[a,b],[c,d]].\",\n",
    "        \"Reflect across the x-axis (swap rows).\",\n",
    "        \"Vertical mirror operation on small grid.\",\n",
    "        \"Use top-bottom symmetry to transform the pattern.\",\n",
    "        \"TB reflection mapping instruction.\",\n",
    "        \"Flip top to bottom on the given grid.\"\n",
    "    ],\n",
    "}\n",
    "\n",
    "TEST: List[Tuple[str, str]] = []\n",
    "for cls in (\"rotate\", \"flip_h\", \"flip_v\"):\n",
    "    # 4 test prompts per class (12 total)\n",
    "    samples = [\n",
    "        f\"Test {cls} example 1 on a 2x2 grid.\",\n",
    "        f\"Please {cls.replace('_',' ')} the matrix [[1,2],[3,4]].\",\n",
    "        f\"ARC-style: apply {cls} to the input grid.\",\n",
    "        f\"Execute {cls} transformation for evaluation.\",\n",
    "    ]\n",
    "    for s in samples:\n",
    "        TEST.append((s, cls))\n",
    "\n",
    "# ---------------------------\n",
    "# Embedding utils\n",
    "# ---------------------------\n",
    "_tokenizer: GPT2Tokenizer = None  # type: ignore\n",
    "_model: GPT2LMHeadModel = None  # type: ignore\n",
    "_device = None\n",
    "\n",
    "\n",
    "def load_model(device: str = DEVICE_DEFAULT):\n",
    "    global _tokenizer, _model, _device\n",
    "    _device = torch.device(device)\n",
    "    _tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "    _model = GPT2LMHeadModel.from_pretrained(\"gpt2\").to(_device)\n",
    "    _model.eval()\n",
    "\n",
    "\n",
    "def embed(text: str) -> np.ndarray:\n",
    "    with torch.no_grad():\n",
    "        toks = _tokenizer(text, return_tensors=\"pt\").to(_device)\n",
    "        out = _model(**toks, output_hidden_states=True)\n",
    "        hs = out.hidden_states[-1][0]  # (seq, hidden)\n",
    "        vec = hs.mean(dim=0).detach().cpu().numpy()  # (hidden,)\n",
    "        return vec.astype(np.float64)\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# PCA + scaler\n",
    "# ---------------------------\n",
    "@dataclass\n",
    "class Projector:\n",
    "    scaler: StandardScaler\n",
    "    pca: PCA\n",
    "\n",
    "    def transform(self, X: np.ndarray) -> np.ndarray:\n",
    "        Xs = self.scaler.transform(X)\n",
    "        return self.pca.transform(Xs)\n",
    "\n",
    "\n",
    "def fit_projector(X: np.ndarray) -> Projector:\n",
    "    scaler = StandardScaler(with_mean=True, with_std=True)\n",
    "    Xs = scaler.fit_transform(X)\n",
    "\n",
    "    # probe n based on variance goal (bounded by PCA_MIN/PCA_MAX and sample cap)\n",
    "    n_samples, n_feats = Xs.shape\n",
    "    hard_cap = min(n_samples, n_feats)\n",
    "    probe_cap = min(hard_cap, PCA_MAX)\n",
    "\n",
    "    p_probe = PCA(n_components=probe_cap, whiten=False, svd_solver=\"full\")\n",
    "    p_probe.fit(Xs)\n",
    "    cum = np.cumsum(p_probe.explained_variance_ratio_)\n",
    "    k = next((i + 1 for i, v in enumerate(cum) if v >= PCA_TARGET_VAR), probe_cap)\n",
    "    k = int(max(PCA_MIN, min(k, probe_cap)))\n",
    "\n",
    "    pca = PCA(n_components=k, whiten=PCA_WHITEN, svd_solver=\"full\")\n",
    "    pca.fit(Xs)\n",
    "\n",
    "    print(f\"[PCA] samples={n_samples} feat={n_feats} cap={hard_cap} -> n={k} (cum var≈{cum[k-1]:.4f}, whiten={PCA_WHITEN})\")\n",
    "    return Projector(scaler, pca)\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# Orientation-aware LDA-like classifier\n",
    "# ---------------------------\n",
    "@dataclass\n",
    "class Classifier:\n",
    "    classes: List[str]\n",
    "    means: Dict[str, np.ndarray]\n",
    "    cov: np.ndarray  # shared covariance (LDA)\n",
    "    inv_cov: np.ndarray\n",
    "    orient_axis: np.ndarray  # direction separating flip_h vs flip_v\n",
    "    flip_center: np.ndarray\n",
    "\n",
    "    def score_components(self, x: np.ndarray) -> Dict[str, Dict[str, float]]:\n",
    "        comps: Dict[str, Dict[str, float]] = {}\n",
    "        for c in self.classes:\n",
    "            mu = self.means[c]\n",
    "            # Cosine similarity\n",
    "            cos = float(np.dot(x, mu) / (np.linalg.norm(x) * np.linalg.norm(mu) + 1e-9))\n",
    "            # Mahalanobis squared distance\n",
    "            d = x - mu\n",
    "            maha2 = float(d.T @ self.inv_cov @ d)\n",
    "            comps[c] = {\"cos\": cos, \"maha2\": maha2}\n",
    "        return comps\n",
    "\n",
    "    def orient_logit(self, x: np.ndarray) -> float:\n",
    "        # Signed alignment along flip_h vs flip_v axis relative to their midpoint\n",
    "        dx = x - self.flip_center\n",
    "        num = float(np.dot(dx, self.orient_axis))\n",
    "        den = float(np.linalg.norm(dx) * np.linalg.norm(self.orient_axis) + 1e-9)\n",
    "        s = num / den\n",
    "        # squash to (−1,1)\n",
    "        return float(np.tanh(2.5 * s))\n",
    "\n",
    "    def fused_logits(self, x: np.ndarray) -> Dict[str, float]:\n",
    "        comps = self.score_components(x)\n",
    "        # base fusion without orientation\n",
    "        logits = {}\n",
    "        for c, z in comps.items():\n",
    "            logits[c] = W_COS * z[\"cos\"] + W_MAHA * (-z[\"maha2\"])  # larger is better\n",
    "        # orientation bonus only for flips\n",
    "        o = self.orient_logit(x)\n",
    "        logits[\"flip_h\"] = logits.get(\"flip_h\", 0.0) + W_ORIENT * max(0.0, o)\n",
    "        logits[\"flip_v\"] = logits.get(\"flip_v\", 0.0) + W_ORIENT * max(0.0, -o)\n",
    "        return logits\n",
    "\n",
    "    def predict_proba(self, x: np.ndarray) -> Tuple[str, np.ndarray, Dict[str, Dict[str, float]]]:\n",
    "        logits = self.fused_logits(x)\n",
    "        # temperature softmax\n",
    "        keys = self.classes\n",
    "        z = np.array([logits[k] for k in keys], dtype=np.float64)\n",
    "        z = z / max(1e-9, TEMP)\n",
    "        # stabilize\n",
    "        z = z - z.max()\n",
    "        p = np.exp(z)\n",
    "        p = p / p.sum()\n",
    "        pred = keys[int(np.argmax(p))]\n",
    "        return pred, p, self.score_components(x)\n",
    "\n",
    "\n",
    "def fit_classifier(X: np.ndarray, y: List[str], classes: List[str]) -> Classifier:\n",
    "    # class means\n",
    "    means = {c: X[np.array([yy == c for yy in y])].mean(axis=0) for c in classes}\n",
    "    # shared covariance (shrinkage for stability)\n",
    "    Xc = np.vstack([X[np.array([yy == c for yy in y])] - means[c] for c in classes])\n",
    "    cov = (Xc.T @ Xc) / max(1, Xc.shape[0] - 1)\n",
    "    # add small ridge for invertibility\n",
    "    cov = cov + 1e-4 * np.eye(cov.shape[0])\n",
    "    inv_cov = inv(cov)\n",
    "\n",
    "    # orientation axis: from flip_v mean to flip_h mean\n",
    "    flip_h_mu = means[\"flip_h\"]\n",
    "    flip_v_mu = means[\"flip_v\"]\n",
    "    orient_axis = flip_h_mu - flip_v_mu\n",
    "    flip_center = 0.5 * (flip_h_mu + flip_v_mu)\n",
    "\n",
    "    return Classifier(classes=classes, means=means, cov=cov, inv_cov=inv_cov,\n",
    "                      orient_axis=orient_axis, flip_center=flip_center)\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# Benchmark\n",
    "# ---------------------------\n",
    "LABELS = [\"flip_h\", \"flip_v\", \"rotate\"]  # fixed order for stability\n",
    "\n",
    "\n",
    "def prepare_data() -> Tuple[np.ndarray, List[str], np.ndarray, List[str], Projector]:\n",
    "    # embed training\n",
    "    X_train, y_train = [], []\n",
    "    for cls, prompts in TRAIN.items():\n",
    "        for s in prompts:\n",
    "            X_train.append(embed(s))\n",
    "            y_train.append(cls)\n",
    "    X_train = np.vstack(X_train)\n",
    "\n",
    "    proj = fit_projector(X_train)\n",
    "    Xr = proj.transform(X_train)\n",
    "\n",
    "    # embed test\n",
    "    X_test, y_test = [], []\n",
    "    for s, cls in TEST:\n",
    "        X_test.append(embed(s))\n",
    "        y_test.append(cls)\n",
    "    X_test = np.vstack(X_test)\n",
    "    X_test_r = proj.transform(X_test)\n",
    "    return Xr, y_train, X_test_r, y_test, proj\n",
    "\n",
    "\n",
    "def run(device: str = DEVICE_DEFAULT):\n",
    "    load_model(device)\n",
    "    Xr, y_train, Xte, y_test, proj = prepare_data()\n",
    "\n",
    "    print(f\"[Anchors] order: {LABELS}\")\n",
    "    clf = fit_classifier(Xr, y_train, classes=LABELS)\n",
    "\n",
    "    # sanity: classwise average distance (euclidean in reduced space)\n",
    "    sanity_dists = []\n",
    "    for c in LABELS:\n",
    "        mu = clf.means[c]\n",
    "        d = np.linalg.norm(Xr - mu, axis=1)\n",
    "        sanity_dists.append(d.mean())\n",
    "    print(f\"[Sanity] distances: [{' '.join(f'{v:.3f}' for v in sanity_dists)}]\")\n",
    "    print(f\"[Sanity] chosen: {LABELS[int(np.argmin(sanity_dists))]}\")\n",
    "\n",
    "    # eval\n",
    "    correct = 0\n",
    "    probs_logged = []\n",
    "    lines = []\n",
    "    for i, (x, true) in enumerate(zip(Xte, y_test), start=1):\n",
    "        pred, p, comps = clf.predict_proba(x)\n",
    "        # enforce rotate margin vs flips (helps when flips dominate geometry)\n",
    "        if pred == \"rotate\":\n",
    "            # compare rotate logit vs best flip logit\n",
    "            logits = clf.fused_logits(x)\n",
    "            best_flip = max(logits[\"flip_h\"], logits[\"flip_v\"])\n",
    "            if logits[\"rotate\"] < best_flip + MARGIN_ROTATE:\n",
    "                pred = \"flip_h\" if logits[\"flip_h\"] >= logits[\"flip_v\"] else \"flip_v\"\n",
    "                # recompute a pseudo-prob vector by nudging\n",
    "                order = [\"flip_h\", \"flip_v\", \"rotate\"]\n",
    "                raw = np.array([logits[o] for o in order]) / TEMP\n",
    "                raw = raw - raw.max()\n",
    "                pp = np.exp(raw)\n",
    "                p = pp / pp.sum()\n",
    "\n",
    "        ok = (pred == true)\n",
    "        conf = float(np.max(p))\n",
    "        # dist* proxy: use mean of (euclidean to class means) weighted by prob\n",
    "        eu_d = np.array([np.linalg.norm(x - clf.means[c]) for c in LABELS])\n",
    "        dist_star = float(np.dot(eu_d, p))\n",
    "\n",
    "        probs_logged.append(p)\n",
    "        lines.append((i, true, pred, ok, dist_star, conf, p))\n",
    "\n",
    "    # print per-sample\n",
    "    for i, true, pred, ok, dist_star, conf, p in lines:\n",
    "        print(f\"[{i:02d}] true={true:<7} pred={pred:<7} ok={str(ok):<5} dist*={dist_star:.3f} conf={conf:.3f} probs=[{p[0]:.3f} {p[1]:.3f} {p[2]:.3f}]\")\n",
    "\n",
    "    # metrics\n",
    "    y_pred = [pred for _, _, pred, *_ in lines]\n",
    "    acc = sum(int(a == b) for a, b in zip(y_pred, y_test)) / len(y_test)\n",
    "    mean_conf = float(np.mean([c for *_, c, _ in lines]))\n",
    "\n",
    "    print(f\"\\n[ARC-12] Accuracy: {100*acc:.1f}% | Mean confidence: {mean_conf:.3f} | Mode=geodesic-LDA-orient\")\n",
    "\n",
    "    # confusion\n",
    "    cm = confusion_matrix(y_test, y_pred, labels=LABELS)\n",
    "    print(\"[Confusion]\\n          pred→   flip_h  flip_v  rotate\")\n",
    "    for i, row in enumerate(cm):\n",
    "        print(f\"true={LABELS[i]:<8}      {row[0]:>3}     {row[1]:>3}     {row[2]:>3}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    ap = argparse.ArgumentParser()\n",
    "    ap.add_argument(\"--device\", type=str, default=DEVICE_DEFAULT)\n",
    "    args = ap.parse_args()\n",
    "    run(device=args.device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd24221-d6d5-4836-95cf-52c2062e2139",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0rc2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
