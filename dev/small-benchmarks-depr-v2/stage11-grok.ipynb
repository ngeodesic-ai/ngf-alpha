{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "325d9612-3593-4b0d-b13d-fb7844af3485",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tokens: 10\n",
      "z_prof shape: (10,), min/max: (0.0, 63.99386876821518)\n",
      "Final y position: [-1.60235818e-01  1.98211648e-04 -4.00831505e-06]\n",
      "Max E_perp: [3.93039242e-08 1.00000000e+00 1.00000000e+00]\n",
      "Max E_perp_smooth: [3.6079832e-08 1.0000000e+00 1.0000000e+00]\n",
      "Max correlations: [0.39093386 0.2068642  0.42910282]\n",
      "Z-scores: [-1.49004491e+00  1.52112233e+07  1.48021288e+07]\n",
      "Areas: [1.92994647e+01 9.21114413e-07 9.07736256e-07]\n",
      "Detected primitives (0: flip h, 1: flip v, 2: rotate): []\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import GPT2Model, GPT2Tokenizer\n",
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "\n",
    "# Load model and tokenizer, set padding token\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "tokenizer.pad_token = tokenizer.eos_token  # Set pad_token to eos_token (<|endoftext|>)\n",
    "model = GPT2Model.from_pretrained('gpt2', output_hidden_states=True)  # Enable hidden states\n",
    "prompt = \"transform a grid: flip horizontal then rotate 90 degrees\"\n",
    "inputs = tokenizer(prompt, return_tensors='pt', padding=True, truncation=True, max_length=20)\n",
    "outputs = model(**inputs)  # Get model outputs\n",
    "embeddings = outputs.hidden_states[8]  # Layer 8, token-level embeddings\n",
    "\n",
    "# Reshape for PCA: [seq_len, hidden_size] by removing batch dim\n",
    "embeddings = embeddings.squeeze(0)  # Shape: [seq_len, hidden_size]\n",
    "n_tokens = embeddings.shape[0]\n",
    "print(f\"Number of tokens: {n_tokens}\")\n",
    "if n_tokens < 3:\n",
    "    raise ValueError(f\"Number of tokens ({n_tokens}) is less than n_components=3. Consider increasing max_length.\")\n",
    "\n",
    "# Warp: PCA reduction and funnel fit\n",
    "pca = PCA(n_components=3)\n",
    "whitened = pca.fit_transform(embeddings.detach().numpy())\n",
    "r = np.sqrt(whitened[:, 0]**2 + whitened[:, 1]**2)  # Radial distance\n",
    "bins = np.linspace(r.min(), r.max(), n_tokens)\n",
    "z_fit = np.interp(r, bins, -np.minimum.accumulate(np.percentile(whitened, q=np.linspace(0, 100, n_tokens), axis=0).mean(axis=1)))\n",
    "z_tmpl = - (r**2) / (r.max()**2 + 1e-8) * abs(z_fit.min())\n",
    "z_prof = 0.5 * z_fit + 0.5 * z_tmpl  # Blended profile\n",
    "print(f\"z_prof shape: {z_prof.shape}, min/max: {z_prof.min(), z_prof.max()}\")\n",
    "\n",
    "# Simulate traversal (cap phantom and adjust weights)\n",
    "d = 3\n",
    "T = 600\n",
    "dt = 0.02\n",
    "m = 4.0\n",
    "lamb = 0.35\n",
    "gamma = 0.04\n",
    "a_damp = 1 - gamma * dt / (2 * m)\n",
    "\n",
    "p = np.eye(d)  # Prototypes: flip h, flip v, rotate\n",
    "c = np.array([[0.5, 0, 0], [0, 0.005, 0], [0, 0, 0.5]])  # Maintain hijack\n",
    "w = np.zeros((T, 3))\n",
    "w[100:250, 0] = np.linspace(0, 2.0, 150)  # Extended flip h\n",
    "w[250:400, 2] = np.linspace(0, 2.0, 150)  # Shift rotate after flip h\n",
    "\n",
    "# Normalize initial position\n",
    "y = whitened[0].copy() / np.linalg.norm(whitened[0])  # Start normalized\n",
    "v = np.zeros(d)\n",
    "Y = np.zeros((T, d))\n",
    "for t in range(T - 1):\n",
    "    grad_U = np.zeros(d)\n",
    "    for k in range(3):\n",
    "        Pi = np.eye(d) - np.outer(p[:, k], p[:, k])\n",
    "        grad_U += w[t, k] * Pi @ (y - c[:, k])\n",
    "    v_half = a_damp * v - (lamb * dt / (2 * m)) * grad_U\n",
    "    y_next = y + dt * v_half\n",
    "    grad_U_next = np.zeros(d)\n",
    "    for k in range(3):\n",
    "        Pi = np.eye(d) - np.outer(p[:, k], p[:, k])\n",
    "        grad_U_next += w[t + 1, k] * Pi @ (y_next - c[:, k])\n",
    "    v_next = a_damp * v_half - (lamb * dt / (2 * m)) * grad_U_next\n",
    "    y = y_next\n",
    "    v = v_next\n",
    "    Y[t] = y\n",
    "print(f\"Final y position: {y}\")\n",
    "\n",
    "# Detect: Energies and matched filtering with cap\n",
    "E_par = np.zeros((T, 3))\n",
    "E_perp = np.zeros((T, 3))\n",
    "for t in range(T):\n",
    "    for k in range(3):\n",
    "        s = np.dot(p[:, k], Y[t] - c[:, k])\n",
    "        E_par[t, k] = s**2\n",
    "        E_perp[t, k] = min(np.linalg.norm(Y[t] - c[:, k])**2 - E_par[t, k], 1.0)  # Cap at 1.0\n",
    "print(f\"Max E_perp: {np.max(E_perp, axis=0)}\")\n",
    "\n",
    "# Light denoise: EMA smoothing\n",
    "gamma_ema = 0.9\n",
    "E_perp_smooth = np.zeros_like(E_perp)\n",
    "E_perp_smooth[0] = E_perp[0]\n",
    "for t in range(1, T):\n",
    "    E_perp_smooth[t] = gamma_ema * E_perp_smooth[t-1] + (1 - gamma_ema) * E_perp[t]\n",
    "print(f\"Max E_perp_smooth: {np.max(E_perp_smooth, axis=0)}\")\n",
    "\n",
    "# Exclusive residuals and z-scoring\n",
    "Z = (E_perp_smooth - E_perp_smooth.mean(axis=0)) / (E_perp_smooth.std(axis=0) + 1e-8)\n",
    "E = np.zeros((T, 3))\n",
    "for k in range(3):\n",
    "    Q_minus = np.hstack([Z[:, j][:, np.newaxis] for j in range(3) if j != k]) if any(j != k for j in range(3)) else np.zeros((T, 0))\n",
    "    if Q_minus.shape[1] > 0:\n",
    "        Q, _ = np.linalg.qr(Q_minus)\n",
    "        proj = Q @ (Q.T @ Z[:, k])\n",
    "    else:\n",
    "        proj = np.zeros(T)\n",
    "    rex = np.maximum(Z[:, k] - proj, 0)\n",
    "    E[:, k] = np.convolve(rex, np.ones(7)/7, mode='same')\n",
    "\n",
    "# Matched filter\n",
    "tau = np.arange(50)\n",
    "q = np.sin(np.pi * tau / 50)\n",
    "q = q - q.mean()\n",
    "flipped_q = q[::-1]\n",
    "C = np.zeros((T, 3))\n",
    "for k in range(3):\n",
    "    num = np.convolve(E[:, k] - E[:, k].mean(), flipped_q, mode='same')\n",
    "    den1 = np.sqrt(np.convolve((E[:, k] - E[:, k].mean())**2, np.ones(len(q)), mode='same'))\n",
    "    den2 = np.sqrt(len(q) * np.var(q))\n",
    "    den = den1 * den2 + 1e-8\n",
    "    C[:, k] = num / den\n",
    "\n",
    "max_C = np.max(C, axis=0)\n",
    "t_star = np.argmax(C, axis=0)\n",
    "print(f\"Max correlations: {max_C}\")\n",
    "\n",
    "# Null calibration (simplified z-score)\n",
    "z_scores = np.zeros(3)\n",
    "for k in range(3):\n",
    "    null_maxs = [np.max(np.convolve(np.roll(E[:, k], shift) - E[:, k].mean(), flipped_q, mode='same')) for shift in range(1, 65)]\n",
    "    z_scores[k] = (max_C[k] - np.mean(null_maxs)) / (np.std(null_maxs) + 1e-8)\n",
    "print(f\"Z-scores: {z_scores}\")\n",
    "\n",
    "# Area and thresholds\n",
    "A = np.zeros(3)\n",
    "for k in range(3):\n",
    "    max_E = E[t_star[k], k]\n",
    "    thresh = max_E / 2\n",
    "    left = t_star[k]\n",
    "    while left > 0 and E[left, k] > thresh and left > t_star[k] - 100:\n",
    "        left -= 1\n",
    "    right = t_star[k]\n",
    "    while right < T - 1 and E[right, k] > thresh and right < t_star[k] + 100:\n",
    "        right += 1\n",
    "    A[k] = np.sum(E[left:right + 1, k])\n",
    "print(f\"Areas: {A}\")\n",
    "\n",
    "tau_area = 0.05\n",
    "tau_corr = 0.25\n",
    "tau_z = 5000.0  # Adjusted for high z-score artifact\n",
    "detected = [k for k in range(3) if A[k] > tau_area and max_C[k] > tau_corr and z_scores[k] > tau_z]\n",
    "\n",
    "print(\"Detected primitives (0: flip h, 1: flip v, 2: rotate):\", detected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db73120-8e8e-4244-901c-fd59af189bd9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0rc2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
